{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60b312c-4e0d-47cc-858d-26dbe300bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.1-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.9.18-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patron\\miniconda3\\envs\\proj1\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl (18.2 MB)\n",
      "Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Using cached aiohttp-3.13.1-cp310-cp310-win_amd64.whl (453 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.7.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Using cached propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "Using cached regex-2025.9.18-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: safetensors, regex, pyarrow, propcache, multidict, joblib, frozenlist, faiss-cpu, dill, async-timeout, aiohappyeyeballs, yarl, scikit-learn, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, sentence-transformers, datasets\n",
      "\n",
      "   ----------------------------------------  0/23 [safetensors]\n",
      "   - --------------------------------------  1/23 [regex]\n",
      "   - --------------------------------------  1/23 [regex]\n",
      "   - --------------------------------------  1/23 [regex]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   --- ------------------------------------  2/23 [pyarrow]\n",
      "   ----- ----------------------------------  3/23 [propcache]\n",
      "   ------ ---------------------------------  4/23 [multidict]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   -------- -------------------------------  5/23 [joblib]\n",
      "   ---------- -----------------------------  6/23 [frozenlist]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------ ---------------------------  7/23 [faiss-cpu]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ------------- --------------------------  8/23 [dill]\n",
      "   ----------------- ---------------------- 10/23 [aiohappyeyeballs]\n",
      "   ------------------- -------------------- 11/23 [yarl]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   -------------------- ------------------- 12/23 [scikit-learn]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ---------------------- ----------------- 13/23 [pandas]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   ------------------------ --------------- 14/23 [multiprocess]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   -------------------------- ------------- 15/23 [huggingface-hub]\n",
      "   --------------------------- ------------ 16/23 [aiosignal]\n",
      "   ----------------------------- ---------- 17/23 [tokenizers]\n",
      "   ----------------------------- ---------- 17/23 [tokenizers]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   ------------------------------- -------- 18/23 [aiohttp]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   --------------------------------- ------ 19/23 [accelerate]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ---------------------------------- ----- 20/23 [transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   ------------------------------------ --- 21/23 [sentence-transformers]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   ---------------------------------------- 23/23 [datasets]\n",
      "\n",
      "Successfully installed accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 async-timeout-5.0.1 datasets-4.2.0 dill-0.4.0 faiss-cpu-1.12.0 frozenlist-1.8.0 huggingface-hub-0.35.3 joblib-1.5.2 multidict-6.7.0 multiprocess-0.70.16 pandas-2.3.3 propcache-0.4.1 pyarrow-21.0.0 regex-2025.9.18 safetensors-0.6.2 scikit-learn-1.7.2 sentence-transformers-5.1.1 tokenizers-0.22.1 transformers-4.57.1 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "# --- Install dependencies (run once) ---\n",
    "# In Jupyter, uncomment this line if you haven't installed them yet:\n",
    "!pip install datasets sentence-transformers faiss-cpu transformers accelerate tqdm\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a58232-9b4b-4a62-b1ad-541faa7f6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Save directory set to: ./timeqa_tempralm\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"./timeqa_tempralm\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(\" Save directory set to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d91346-8f4b-41c9-8370-826387ad4c8f",
   "metadata": {},
   "source": [
    "Retrieval-side preprocessing stage of a Temporal RAG \n",
    "Data ingestion + Temporal feature extraction\n",
    "\n",
    "This code loads and preprocesses the TimeQA dataset (a temporal question-answering dataset) by extracting year information from each question and context passage. It adds this temporal metadata to each example and then saves the processed dataset locally.\n",
    "\n",
    "extract_year function searches a given text for a year pattern. Returns the integer year if found, else None.\n",
    "add_years function extracts the year from the question (q_year) and the context (d_year). If the question doesnt have a year but the context does, it copies the context year to q_year. Adds two new fields:\n",
    "\"query_year\"  year related to the question\n",
    "\"doc_year\"  year related to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f44bee-5f1f-4595-8390-cc0e1515ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b24b35b5ec4abd9486ade5a1d797de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patron\\miniconda3\\envs\\proj1\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Patron\\.cache\\huggingface\\hub\\datasets--hugosousa--TimeQA. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b32c8157dd482c81ba9a0a1ee06262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.json:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cecd0e364c4ea981d1eef956c74ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.json:   0%|          | 0.00/65.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d7e4adafac415e82f6164a4b67de61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.json:   0%|          | 0.00/64.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b238b436b6b4fb5880c2264d671f8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/28989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d51d98d71a94be38ff6bd17cc19c0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bccc71e026142d5ac93082030e5458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c746998bcce476692991a3a5ad62ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91876d997dd54f59b93c6ed5e4f1688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a388184f79974f0f8294812923d4da21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal metadata extracted.\n",
      "{'targets': ['Ulster Unionist MP for South Antrim'], 'level': 'easy', 'question': 'Which position did Knox Cunningham hold from May 1955 to Apr 1956?', 'idx': '/wiki/Knox_Cunningham#P39#0', 'context': 'Knox Cunningham Sir Samuel Knox Cunningham , 1st Baronet , QC ( 3 April 1909  29 July 1976 ) , was a Northern Irish barrister , businessman and politician . As an Ulster Unionist politician at a time when the Unionists were part of the Conservative Party , he was also a significant figure in United Kingdom politics as Parliamentary Private Secretary to Harold Macmillan . His nephew was Sir Josias Cunningham . Early career . Cunningham was from an Ulster family . His father was Samuel Cunningham , and his mother was Janet Muir Knox ( nee McCosh ) of Dalry , Ayrshire . His elder brothers were Colonel James Glencairn Cunningham , Josias Cunningham stockbroker , Dunlop McCosh Cunningham owner of Murrays tobacco works , Belfast . He was sent to the Royal Belfast Academical Institution , and then to Fettes College in Edinburgh . He then won a place at Clare College , Cambridge - where he was heavy-weight boxing champion . The Cunningham family still remain prominent landowners around the Parkgate area of South Antrim with relatives including great nephews Joe , Richard and Garret still residing on the family estate . The family had considerable business interests in land , Tobacco , commerce and finance . From 1931 Cunningham went into business in Northern Ireland . He married Dorothy Enid Riley JP on 2 July 1935 . Later in the 1930s , Cunningham studied law and was called to the Bar by the Middle Temple in 1939 . During the Second World War he served in the Scots Guards although he continued his legal studies , and called to the Bar in Northern Ireland in 1942 . He fought the Belfast West by-election in 1943 and the same seat in the 1945 general election . After the war Cunningham mainly lived in Orpington , although he retained membership of the Ulster Unionist Council . His religious faith led him to be involved with the World Alliance of YMCAs from 1947 , and he was Chairman of the National Council of the YMCA in 1949 . In 1954 he was elected to Orpington Urban District Council . Later he maintained a home , the Derhams House , near Minchinhampton . Parliament . In the 1955 general election , Cunningham was chosen as the new Ulster Unionist MP for South Antrim . He was a delegate to the Council of Europe and Western European Union Parliamentary Assembly from 1956 to 1959 . He also served as Parliamentary Private Secretary to Jocelyn Simon , Financial Secretary to the Treasury , from 1958 . In 1959 he was made a Queens Counsel . After the 1959 general election , Cunningham was picked by Prime Minister Harold Macmillan as his Parliamentary Private Secretary , responsible for the Prime Ministers relations with backbench Conservative MPs . He was also a member of the National Executive of the Conservative and Unionist Party . When Macmillan resigned , he awarded Cunningham a baronetcy in his resignation honours . Post-Parliamentary career . Cunningham remained on the backbenches , known as one to the right of Ulster Unionism and a friend of Ian Paisley , through the rest of the 1960s , he frequently clashed with Harold Wilson during this period , but decided to retire at the 1970 general election . He was Master of the Drapers Company in 197374 . He was Provincial Grand Master of the Masonic Order in Gloucestershire from 1970-76 . He was a member of the Apprentice Boys Club in Derry and attended the 275th Anniversary of the shutting of the gates . Throughout his life he represented the old landed interests of Ulster and remained personally wealthy through family inheritance . He died suddenly at Derhams House , Minchinhampton on 29 July 1976 at the age of sixty-seven . Military intelligence , the RUC and victims named Cunningham as a paedophile and identified his close links to the sex offender ring at Kincora Boys Home but MI5 deny this . Sources . - M . Stenton and S . Lees , Whos Who of British MPs , vol . IV ( Harvester Press , 1981 ) .', 'query_year': 1955, 'doc_year': 1909}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77a1ab82d474817b04b0fb994f5139a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/28989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304c8a61be114aaaa27cacf4c432864f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a456a53d61648feb9e23fe8c711e362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "ds = load_dataset(\"hugosousa/TimeQA\")\n",
    "\n",
    "year_regex = re.compile(r\"(19|20)\\d{2}\")\n",
    "\n",
    "def extract_year(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    m = year_regex.search(text)\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def add_years(example):\n",
    "    q_year = extract_year(example[\"question\"])\n",
    "    d_year = extract_year(example[\"context\"])\n",
    "    if q_year is None and d_year is not None:\n",
    "        q_year = d_year\n",
    "    example[\"query_year\"] = q_year\n",
    "    example[\"doc_year\"] = d_year\n",
    "    return example\n",
    "\n",
    "ds = ds.map(add_years)\n",
    "print(\"Temporal metadata extracted.\")\n",
    "print(ds[\"train\"][0])\n",
    "\n",
    "# Save processed dataset\n",
    "ds.save_to_disk(f\"{SAVE_DIR}/timeqa_with_years\")\n",
    "print(\"Saved processed dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fa390-784d-4b92-93e4-466583f66afc",
   "metadata": {},
   "source": [
    "Retrieval data preparation phase - Passage building / indexing input prep\n",
    "\n",
    "This code formats and serializes the documents (contexts) from the TimeQA dataset into temporally-tagged passages that can later be embedded and indexed for retrieval in a RAG system.\n",
    "\n",
    "This build_passage function takes one example (row) from the dataset.\n",
    "If the context has a known year (doc_year), it prepends a special temporal token like: [DATE: 1995] The Berlin Wall fell in 1989...\n",
    "If theres no year, it uses [DATE: unknown].\n",
    "Returns a dictionary with a new key \"passage\" that stores this formatted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a1e31a-2c83-4665-b0bb-d05dd22dbd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e58addc6a4b483ab2a34efde95e95dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637353ae007e40fe92058ed6c43427b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a59d2b6434048a7817b42d5a84dc0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Passages built and saved. Example:\n",
      " [DATE: 1909] Knox Cunningham Sir Samuel Knox Cunningham , 1st Baronet , QC ( 3 April 1909  29 July 1976 ) , was a Northern Irish barrister , businessman and politician . As an Ulster Unionist politic\n"
     ]
    }
   ],
   "source": [
    "def build_passage(example):\n",
    "    year_token = f\"[DATE: {example['doc_year']}]\" if example.get(\"doc_year\") else \"[DATE: unknown]\"\n",
    "    passage = f\"{year_token} {example.get('context','')}\"\n",
    "    return {\"passage\": passage}\n",
    "\n",
    "ds = ds.map(build_passage)\n",
    "train_passages = [x[\"passage\"] for x in ds[\"train\"]]\n",
    "train_years = [x[\"doc_year\"] for x in ds[\"train\"]]\n",
    "\n",
    "with open(f\"{SAVE_DIR}/train_passages.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"passages\": train_passages, \"years\": train_years}, f)\n",
    "\n",
    "print(\" Passages built and saved. Example:\\n\", train_passages[0][:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013d8ba-f305-44f2-9a18-c191997d90f1",
   "metadata": {},
   "source": [
    "Indexing and retrieval setup - Embedding & indexing\n",
    "\n",
    "This code creates (or loads) a FAISS vector index of all the temporally tagged passages created earlier.\n",
    "\n",
    "It uses a Sentence Transformer encoder (all-MiniLM-L6-v2) to turn each passage into a dense embedding vector, normalizes them, and stores them in a FAISS index for fast similarity search during retrieval.\n",
    "\n",
    "If the index files already exist  load them.\n",
    "Else  build the index from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad0e0ee-0cbe-4cb3-8ee1-3bb20a1578e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a67412015345cb872d859c3e3fea19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patron\\miniconda3\\envs\\proj1\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Patron\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3028f9e8e474bb8a1af0e77ead08cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d255be7de6a4a60a5809e3b7482e810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703b008b3f2a49b79fbc8c4272bac662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce7b398d77e45df99453af8c65d5319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01deeb20b6e54e15a5637f8c9312fb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4a7fceae2f45388850ad8881783331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8f4896129b4019b9f96565675dae68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65720d692b184be3a26083d365881441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c037b58fd3b345c6ba0f4249500cf313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cacab23d5e409abaaf7e948315fbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Encoding passages... (this may take a few hours on CPU)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfaf6bdc95b4225a67e01aae3118d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FAISS index built and saved.\n",
      " Index ready with 28989 documents.\n"
     ]
    }
   ],
   "source": [
    "encoder_name = \"all-MiniLM-L6-v2\"\n",
    "encoder = SentenceTransformer(encoder_name)\n",
    "encoder.max_seq_length = 512\n",
    "\n",
    "index_path = f\"{SAVE_DIR}/timeqa_index.faiss\"\n",
    "meta_path = f\"{SAVE_DIR}/index_meta.pkl\"\n",
    "\n",
    "if os.path.exists(index_path) and os.path.exists(meta_path):\n",
    "    print(\" Found existing FAISS index  loading...\")\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(meta_path, \"rb\") as f:\n",
    "        meta = pickle.load(f)\n",
    "    train_years = meta[\"train_years\"]\n",
    "else:\n",
    "    print(\" Encoding passages... (this may take a few hours on CPU)\")\n",
    "    embs = encoder.encode(train_passages, batch_size=256, show_progress_bar=True, convert_to_numpy=True)\n",
    "    faiss.normalize_L2(embs)\n",
    "    index = faiss.IndexFlatIP(embs.shape[1])\n",
    "    index.add(embs)\n",
    "    faiss.write_index(index, index_path)\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        pickle.dump({\"encoder\": encoder_name, \"train_years\": train_years}, f)\n",
    "    print(\" FAISS index built and saved.\")\n",
    "\n",
    "print(\" Index ready with\", index.ntotal, \"documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aaf26b-ef45-4b40-bd8d-91142e9f91a5",
   "metadata": {},
   "source": [
    "Retrieval (Temporal-Aware) - retrieves semantically + temporally relevant docs\n",
    "\n",
    "This code defines a temporally aware retrieval function for your Temporal RAG system.\n",
    "It combines semantic similarity (from FAISS embeddings) with a temporal compatibility score between the querys year (q_year) and each documents year (d_year), ensuring retrieved passages make temporal sense.\n",
    "Essentially, it retrieves passages that are: Semantically relevant, and Temporally consistent (not from the future relative to the query)\n",
    "It uses temporal score formula.\n",
    "\n",
    "If either year is missing  return 0.0 (neutral).\n",
    "\n",
    "If document year is after the query year  penalize heavily (-1e9)  prevents future leakage.\n",
    "Otherwise, assign a score inversely proportional to how far apart the years are:\n",
    "temporalscore=  / 1+q_yeard_year\n",
    "So documents closer in time get higher scores.\n",
    "\n",
    "Semantic retrieval -> Extract candidate years and semantic scores -> Compute temporal scores -> Normalize temporal scores -> Combine & select top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff4c8a2-f169-4b1d-9564-a28852d1a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_SCALE = 1.0\n",
    "OVER_RETRIEVE = 50\n",
    "TOP_K = 5\n",
    "\n",
    "def temporal_score_raw(q_year, d_year, alpha=ALPHA_SCALE):\n",
    "    if q_year is None or d_year is None:\n",
    "        return 0.0\n",
    "    if d_year > q_year:\n",
    "        return -1e9\n",
    "    diff = abs(q_year - d_year)\n",
    "    return alpha / (1.0 + diff)\n",
    "\n",
    "def retrieve_tempralm(query_text, query_year=None, over_retrieve=OVER_RETRIEVE, top_k=TOP_K):\n",
    "    q_emb = encoder.encode([query_text], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, over_retrieve)\n",
    "    D, I = D[0], I[0]\n",
    "    sem_scores = np.array(D, dtype=float)\n",
    "    candidate_years = [train_years[i] for i in I]\n",
    "\n",
    "    temp_raw = np.array([temporal_score_raw(query_year, y) for y in candidate_years], dtype=float)\n",
    "    mask_future = temp_raw < -1e8\n",
    "\n",
    "    if np.all(np.isclose(temp_raw, 0)) or np.nanstd(temp_raw) == 0:\n",
    "        temp_norm = np.zeros_like(temp_raw)\n",
    "        temp_norm[mask_future] = -1e9\n",
    "    else:\n",
    "        mu_tau = np.mean(temp_raw[~mask_future])\n",
    "        sigma_tau = np.std(temp_raw[~mask_future])\n",
    "        mu_s, sigma_s = np.mean(sem_scores), np.std(sem_scores)\n",
    "        temp_norm = ((temp_raw - mu_tau) / (sigma_tau + 1e-12)) * sigma_s + mu_s\n",
    "        temp_norm[mask_future] = -1e9\n",
    "\n",
    "    combined = sem_scores + temp_norm\n",
    "    topk = np.argsort(combined)[::-1][:top_k]\n",
    "    final_docs = [train_passages[I[i]] for i in topk]\n",
    "    final_scores = combined[topk]\n",
    "    return final_docs, final_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3cee9-a7f8-45b0-987c-b14ee6aa4bb0",
   "metadata": {},
   "source": [
    "Generation component of Retrieval-Augmented Generation (RAG) pipeline\n",
    "\n",
    "Loads T5-base, a seq2seq model ideal for question answering and summarization.\n",
    "Takes a query (question) and a list of retrieved documents (contexts) from your temporal retriever.\n",
    "\n",
    "Tokenize and truncate to fit model input size -> Generate output -> Decode the tokens\n",
    "temporal retriever (retrieve_tempralm) = retrieval module (R)\n",
    "T5 generator (generate_answer) = generation module (G)\n",
    "Together  form a RAG system with temporal awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f4eaf-9674-4261-be7d-5a9c540f8f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d6c13be9ab48058d91cd684c4becb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patron\\miniconda3\\envs\\proj1\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Patron\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918f2134f67747d6971efed0b9aeab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a6de62b2ba48a8ae88f273e7dd1dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72db84f4d7274c6bbe11c10354783e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "GEN_MODEL = \"t5-base\"\n",
    "\n",
    "tokenizer_gen = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
    "model_gen = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL).to(device)\n",
    "\n",
    "def generate_answer(query, contexts, max_new_tokens=64):\n",
    "    context = \" \".join(contexts)\n",
    "    prompt = f\"Question: {query}\\nContext: {context}\\nAnswer:\"\n",
    "    inputs = tokenizer_gen(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    out = model_gen.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer_gen.decode(out[0], skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7329422-d3c5-4a45-adf3-0f5b5ba1aa85",
   "metadata": {},
   "source": [
    "Evaluation / Comparison\n",
    "\n",
    "Compares the generated answer with the datasets reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e1056b2-88b3-4e84-8d93-5847608797ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who was the chair of Odder Municipality from 2006 to Dec 2009? | q_year: 2006\n",
      "Generated Answer: Henricus Gregorius Jozeph Henk Kamp\n",
      "Ground Truth: ['']\n"
     ]
    }
   ],
   "source": [
    "sample = ds[\"validation\"][20]\n",
    "query = sample[\"question\"]\n",
    "q_year = sample[\"query_year\"]\n",
    "print(\"Query:\", query, \"| q_year:\", q_year)\n",
    "\n",
    "retrieved_docs, _ = retrieve_tempralm(query, q_year)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "\n",
    "print(\"Generated Answer:\", answer)\n",
    "print(\"Ground Truth:\", sample[\"targets\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfb58a-ea58-4e8b-9cf3-cdf85883b9e9",
   "metadata": {},
   "source": [
    "Evaluation stage of the Temporal RAG pipeline\n",
    "\n",
    "This block compares how well:\n",
    "a standard RAG model (semantic-only retrieval), and a temporal RAG model (semantic + time-aware retrieval)\n",
    "perform on a random subset of validation questions.\n",
    "\n",
    "| Step                     | Module             | Function                             |\n",
    "| ------------------------ | ------------------ | ------------------------------------ |\n",
    "| **Retriever**            | Baseline retriever | `retrieve_semantic_only()`           |\n",
    "| **Retriever (temporal)** | Temporal retriever | `retrieve_tempralm()`                |\n",
    "| **Generator**            | T5 generator       | `generate_answer()`                  |\n",
    "| **Evaluator**            | Comparison metric  | `exact_match()`, `evaluate_subset()` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "421bfd7e-6f23-4b24-b73c-1390372e8da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [26:29<00:00,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results: {'baseline_acc': 0.1, 'tempralm_acc': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_semantic_only(query, top_k=TOP_K):\n",
    "    q_emb = encoder.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    return [train_passages[i] for i in I[0]]\n",
    "\n",
    "def exact_match(pred, gold):\n",
    "    return gold.lower().strip() in pred.lower().strip()\n",
    "\n",
    "def evaluate_subset(n=50, seed=42):\n",
    "    random.seed(seed)\n",
    "    subset = random.sample(list(ds[\"validation\"]), n)\n",
    "    baseline_correct = temp_correct = 0\n",
    "\n",
    "    for ex in tqdm(subset):\n",
    "        q, q_year = ex[\"question\"], ex[\"query_year\"]\n",
    "        gold = ex[\"targets\"]\n",
    "        if isinstance(gold, list):\n",
    "            gold = gold[0] if gold else \"\"\n",
    "\n",
    "        base_docs = retrieve_semantic_only(q)\n",
    "        base_ans = generate_answer(q, base_docs)\n",
    "        if exact_match(base_ans, gold): baseline_correct += 1\n",
    "\n",
    "        tr_docs, _ = retrieve_tempralm(q, q_year)\n",
    "        tr_ans = generate_answer(q, tr_docs)\n",
    "        if exact_match(tr_ans, gold): temp_correct += 1\n",
    "\n",
    "    results = {\n",
    "        \"baseline_acc\": baseline_correct / n,\n",
    "        \"tempralm_acc\": temp_correct / n\n",
    "    }\n",
    "    return results\n",
    "\n",
    "results = evaluate_subset(n=200)\n",
    "print(\" Results:\", results)\n",
    "\n",
    "with open(f\"{SAVE_DIR}/eval_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbcc344-1138-4ae1-a127-ddc398c2b13d",
   "metadata": {},
   "source": [
    "The Results:\n",
    "    \n",
    "| Model                            | Accuracy (Exact Match) |\n",
    "| -------------------------------- | ---------------------- |\n",
    "| **Baseline (semantic-only RAG)** | 0.10  **10%**         |\n",
    "| **Temporal RAG**                 | 0.11  **11%**         |\n",
    "\n",
    "Temporal RAG performs slightly better (+1%) than the plain semantic RAG.\n",
    "That small bump suggests that temporal reasoning helps a bit  the model retrieves slightly more relevant or time-consistent documents.\n",
    "Retrieval/generation pipeline still needs more optimization. (makes us want to try M-RAG, TA-RAG and variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa783404-a421-4478-8ad9-a95b67df951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " RUNNING DIAGNOSTIC ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "TEMPORAL COVERAGE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Query has year: 97/100 (97.0%)\n",
      "Doc has year: 97/100 (97.0%)\n",
      "Both have year: 97/100 (97.0%)\n",
      "\n",
      " Your temporal approach can only help 97/100 (97.0%) questions\n",
      "\n",
      "============================================================\n",
      "EXAMPLES WITHOUT QUERY YEAR:\n",
      "============================================================\n",
      "\n",
      "1. What position did Ecgfrith of Northumbria take from 670 to 685?\n",
      "   Answer: ['King of Northumbria']\n",
      "\n",
      "2. What was the position of Bernard A. Maguire from 1866 to 1870?\n",
      "   Answer: ['president of Georgetown University']\n",
      "\n",
      "3. What position did Ecgfrith of Northumbria take from 664 to 670?\n",
      "   Answer: ['King of Deira']\n",
      "Analyzing failures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:24<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FAILURE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Total analyzed: 50\n",
      "\n",
      " Correct answers: 6 (12.0%)\n",
      "\n",
      " Retrieval failed (gold not in docs): 40 (80.0%)\n",
      " Generation failed (gold in docs, wrong answer): 4 (8.0%)\n",
      " Partial matches: 9 (18.0%)\n",
      "\n",
      "============================================================\n",
      "EXAMPLE RETRIEVAL FAILURES:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Question: Pablo Casado went to which school in Mar 2009?\n",
      "Gold: King Juan Carlos University\n",
      "Predicted: Wharton School\n",
      "Top retrieved doc: [DATE: 1941] Raul Roco Raul Sagarbarria Roco ( October 26 , 1941  August 5 , 2005 ) was a political figure in the Philippines . He was the standard-bearer of Aksyon Demokratiko , which he founded in ...\n",
      "\n",
      "Example 2:\n",
      "Question: Which team did Simon Lappin play for from 2004 to 2005?\n",
      "Gold: Scotland Under-21\n",
      "Predicted: Edinburgh Rugby\n",
      "Top retrieved doc: [DATE: 1979] Simon Taylor ( rugby union ) Simon Marcus Taylor ( born 17 August 1979 ) is a Scottish retired professional rugby union footballer who played for Bath Rugby , Stade Franais and Edinburgh...\n",
      "\n",
      "Example 3:\n",
      "Question: Which team did A. J. DeLaGarza play for between Feb 2017 and Nov 2017?\n",
      "Gold: Houston Dynamo\n",
      "Predicted: Niendorfer TSV\n",
      "Top retrieved doc: [DATE: 1976] Nico Patschinski Nico Patschinski ( born 8 November 1976 in Berlin ) is a former German footballer who last played for Niendorfer TSV . Career . 19801994 : Youth and rise with Union . Pa...\n",
      "\n",
      "============================================================\n",
      "EXAMPLE GENERATION FAILURES:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Question: What operated GCR Class 8B between Sep 1919 and Nov 1921?\n",
      "Gold: Great Central Railway\n",
      "Predicted: GWR Star Class\n",
      "(Gold WAS in retrieved docs!)\n",
      "\n",
      "Example 2:\n",
      "Question: Marietje Schaake became a member of what organization or association in Jul 2009?\n",
      "Gold: European Parliament ( MEP )\n",
      "Predicted: Schwebheim Junge Union\n",
      "(Gold WAS in retrieved docs!)\n",
      "\n",
      "Example 3:\n",
      "Question: What was the name of the employer Vito Volterra work for from 1893 to 1900?\n",
      "Gold: University of Turin\n",
      "Predicted: University of Rome La Sapienza\n",
      "(Gold WAS in retrieved docs!)\n",
      "\n",
      "============================================================\n",
      "SUCCESSFUL EXAMPLES:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Question: What was the name of Fort McMurray from Jun 1962 to Jun 1963?\n",
      "Gold: Fort McMurray\n",
      "Predicted: Fort McMurray\n",
      "\n",
      "Example 2:\n",
      "Question: What organization or association or team did Aaron Ciechanover join in 2007?\n",
      "Gold: \n",
      "Predicted: Carolina RailHawks\n",
      "\n",
      "Example 3:\n",
      "Question: What was the position of Alex Mooney from 2015 to 2019?\n",
      "Gold: \n",
      "Predicted: a striker\n",
      "\n",
      "Comparing retrieval quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:18<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RETRIEVAL COMPARISON\n",
      "============================================================\n",
      "\n",
      "TempRALM retrieves gold better: 1/50 (2.0%)\n",
      "Baseline retrieves gold better: 2/50 (4.0%)\n",
      "Both retrieve gold: 8/50 (16.0%)\n",
      "\n",
      "Evaluating with F1 scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [17:18<00:00, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXACT MATCH vs F1 COMPARISON\n",
      "============================================================\n",
      "\n",
      "Baseline:\n",
      "  Exact Match: 10.00%\n",
      "  F1 Score: 7.85%\n",
      "\n",
      "TempRALM:\n",
      "  Exact Match: 12.00%\n",
      "  F1 Score: 8.97%\n",
      "\n",
      "F1 Improvement: +1.1 points\n",
      "\n",
      "================================================================================\n",
      " DIAGNOSTIC SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. Temporal Coverage: 97.0% of questions have both query & doc years\n",
      "2. Retrieval helps: TempRALM retrieves gold better in 1 cases\n",
      "3. With F1 metric: Baseline 7.9%, TempRALM 9.0%\n",
      "\n",
      " Key Insights:\n",
      "Temporal scoring not improving retrieval much\n",
      " F1 shows better improvement than exact match - predictions are partially correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============= DIAGNOSTIC ANALYSIS =============\n",
    "\n",
    "def analyze_failures(n=50, seed=42):\n",
    "    \"\"\"\n",
    "    Analyze WHY the model is failing\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    subset = random.sample(list(ds[\"validation\"]), min(n, len(ds[\"validation\"])))\n",
    "    \n",
    "    failure_analysis = {\n",
    "        'retrieval_failed': [],  # Gold not in retrieved docs\n",
    "        'generation_failed': [],  # Gold in docs but wrong generation\n",
    "        'both_succeeded': [],     # Got it right\n",
    "        'partial_match': []       # Close but not exact\n",
    "    }\n",
    "    \n",
    "    print(\"Analyzing failures...\")\n",
    "    \n",
    "    for ex in tqdm(subset):\n",
    "        q = ex[\"question\"]\n",
    "        q_year = ex[\"query_year\"]\n",
    "        gold = ex[\"targets\"]\n",
    "        if isinstance(gold, list):\n",
    "            gold = gold[0] if gold else \"\"\n",
    "        \n",
    "        # Get TempRALM results\n",
    "        tr_docs, _ = retrieve_tempralm(q, q_year)\n",
    "        tr_ans = generate_answer(q, tr_docs)\n",
    "        \n",
    "        # Check if gold is in retrieved docs\n",
    "        gold_in_docs = any(gold.lower() in doc.lower() for doc in tr_docs)\n",
    "        \n",
    "        # Check if answer is correct\n",
    "        answer_correct = exact_match(tr_ans, gold)\n",
    "        \n",
    "        # Categorize\n",
    "        if answer_correct:\n",
    "            failure_analysis['both_succeeded'].append({\n",
    "                'question': q,\n",
    "                'gold': gold,\n",
    "                'prediction': tr_ans\n",
    "            })\n",
    "        elif gold_in_docs and not answer_correct:\n",
    "            failure_analysis['generation_failed'].append({\n",
    "                'question': q,\n",
    "                'gold': gold,\n",
    "                'prediction': tr_ans,\n",
    "                'retrieved_docs': tr_docs\n",
    "            })\n",
    "        elif not gold_in_docs:\n",
    "            failure_analysis['retrieval_failed'].append({\n",
    "                'question': q,\n",
    "                'gold': gold,\n",
    "                'prediction': tr_ans,\n",
    "                'retrieved_docs': tr_docs\n",
    "            })\n",
    "        \n",
    "        # Check partial matches\n",
    "        if not answer_correct:\n",
    "            pred_tokens = set(tr_ans.lower().split())\n",
    "            gold_tokens = set(gold.lower().split())\n",
    "            overlap = len(pred_tokens & gold_tokens)\n",
    "            if overlap > 0:\n",
    "                failure_analysis['partial_match'].append({\n",
    "                    'question': q,\n",
    "                    'gold': gold,\n",
    "                    'prediction': tr_ans,\n",
    "                    'overlap': overlap\n",
    "                })\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FAILURE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTotal analyzed: {n}\")\n",
    "    print(f\"\\n Correct answers: {len(failure_analysis['both_succeeded'])} ({len(failure_analysis['both_succeeded'])/n*100:.1f}%)\")\n",
    "    print(f\"\\n Retrieval failed (gold not in docs): {len(failure_analysis['retrieval_failed'])} ({len(failure_analysis['retrieval_failed'])/n*100:.1f}%)\")\n",
    "    print(f\" Generation failed (gold in docs, wrong answer): {len(failure_analysis['generation_failed'])} ({len(failure_analysis['generation_failed'])/n*100:.1f}%)\")\n",
    "    print(f\" Partial matches: {len(failure_analysis['partial_match'])} ({len(failure_analysis['partial_match'])/n*100:.1f}%)\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE RETRIEVAL FAILURES:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, ex in enumerate(failure_analysis['retrieval_failed'][:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Question: {ex['question']}\")\n",
    "        print(f\"Gold: {ex['gold']}\")\n",
    "        print(f\"Predicted: {ex['prediction']}\")\n",
    "        print(f\"Top retrieved doc: {ex['retrieved_docs'][0][:200]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE GENERATION FAILURES:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, ex in enumerate(failure_analysis['generation_failed'][:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Question: {ex['question']}\")\n",
    "        print(f\"Gold: {ex['gold']}\")\n",
    "        print(f\"Predicted: {ex['prediction']}\")\n",
    "        print(f\"(Gold WAS in retrieved docs!)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUCCESSFUL EXAMPLES:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, ex in enumerate(failure_analysis['both_succeeded'][:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Question: {ex['question']}\")\n",
    "        print(f\"Gold: {ex['gold']}\")\n",
    "        print(f\"Predicted: {ex['prediction']}\")\n",
    "    \n",
    "    return failure_analysis\n",
    "\n",
    "\n",
    "def check_temporal_coverage(n=100, seed=42):\n",
    "    \"\"\"\n",
    "    Check if questions actually have temporal information\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    subset = random.sample(list(ds[\"validation\"]), min(n, len(ds[\"validation\"])))\n",
    "    \n",
    "    has_q_year = 0\n",
    "    has_d_year = 0\n",
    "    has_both = 0\n",
    "    \n",
    "    examples_no_year = []\n",
    "    \n",
    "    for ex in subset:\n",
    "        q_year = ex.get('query_year')\n",
    "        d_year = ex.get('doc_year')\n",
    "        \n",
    "        if q_year:\n",
    "            has_q_year += 1\n",
    "        if d_year:\n",
    "            has_d_year += 1\n",
    "        if q_year and d_year:\n",
    "            has_both += 1\n",
    "        \n",
    "        if not q_year:\n",
    "            examples_no_year.append(ex)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEMPORAL COVERAGE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nQuery has year: {has_q_year}/{n} ({has_q_year/n*100:.1f}%)\")\n",
    "    print(f\"Doc has year: {has_d_year}/{n} ({has_d_year/n*100:.1f}%)\")\n",
    "    print(f\"Both have year: {has_both}/{n} ({has_both/n*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n Your temporal approach can only help {has_both}/{n} ({has_both/n*100:.1f}%) questions\")\n",
    "    \n",
    "    if examples_no_year:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EXAMPLES WITHOUT QUERY YEAR:\")\n",
    "        print(\"=\"*60)\n",
    "        for i, ex in enumerate(examples_no_year[:5]):\n",
    "            print(f\"\\n{i+1}. {ex['question']}\")\n",
    "            print(f\"   Answer: {ex['targets']}\")\n",
    "    \n",
    "    return {\n",
    "        'has_q_year': has_q_year,\n",
    "        'has_d_year': has_d_year,\n",
    "        'has_both': has_both,\n",
    "        'coverage': has_both / n\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_retrieval_directly(n=50, seed=42):\n",
    "    \"\"\"\n",
    "    Compare what baseline vs temporal retrieves\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    subset = random.sample(list(ds[\"validation\"]), min(n, len(ds[\"validation\"])))\n",
    "    \n",
    "    better_retrieval = 0\n",
    "    worse_retrieval = 0\n",
    "    same_retrieval = 0\n",
    "    \n",
    "    print(\"\\nComparing retrieval quality...\")\n",
    "    \n",
    "    for ex in tqdm(subset):\n",
    "        q = ex[\"question\"]\n",
    "        q_year = ex[\"query_year\"]\n",
    "        gold = ex[\"targets\"]\n",
    "        if isinstance(gold, list):\n",
    "            gold = gold[0] if gold else \"\"\n",
    "        \n",
    "        # Baseline retrieval\n",
    "        base_docs = retrieve_semantic_only(q, top_k=5)\n",
    "        base_has_gold = any(gold.lower() in doc.lower() for doc in base_docs)\n",
    "        \n",
    "        # Temporal retrieval\n",
    "        temp_docs, _ = retrieve_tempralm(q, q_year, top_k=5)\n",
    "        temp_has_gold = any(gold.lower() in doc.lower() for doc in temp_docs)\n",
    "        \n",
    "        if temp_has_gold and not base_has_gold:\n",
    "            better_retrieval += 1\n",
    "        elif base_has_gold and not temp_has_gold:\n",
    "            worse_retrieval += 1\n",
    "        elif base_has_gold and temp_has_gold:\n",
    "            same_retrieval += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RETRIEVAL COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTempRALM retrieves gold better: {better_retrieval}/{n} ({better_retrieval/n*100:.1f}%)\")\n",
    "    print(f\"Baseline retrieves gold better: {worse_retrieval}/{n} ({worse_retrieval/n*100:.1f}%)\")\n",
    "    print(f\"Both retrieve gold: {same_retrieval}/{n} ({same_retrieval/n*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'better': better_retrieval,\n",
    "        'worse': worse_retrieval,\n",
    "        'same': same_retrieval\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_with_relaxed_matching(n=100, seed=42):\n",
    "    \"\"\"\n",
    "    Try relaxed matching (F1 score) instead of exact match\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    subset = random.sample(list(ds[\"validation\"]), min(n, len(ds[\"validation\"])))\n",
    "    \n",
    "    baseline_exact = []\n",
    "    tempralm_exact = []\n",
    "    baseline_f1 = []\n",
    "    tempralm_f1 = []\n",
    "    \n",
    "    print(\"\\nEvaluating with F1 scores...\")\n",
    "    \n",
    "    for ex in tqdm(subset):\n",
    "        q = ex[\"question\"]\n",
    "        q_year = ex[\"query_year\"]\n",
    "        gold = ex[\"targets\"]\n",
    "        if isinstance(gold, list):\n",
    "            gold = gold[0] if gold else \"\"\n",
    "        \n",
    "        # Baseline\n",
    "        base_docs = retrieve_semantic_only(q)\n",
    "        base_ans = generate_answer(q, base_docs)\n",
    "        baseline_exact.append(1 if exact_match(base_ans, gold) else 0)\n",
    "        \n",
    "        # F1 score\n",
    "        pred_tokens = set(base_ans.lower().split())\n",
    "        gold_tokens = set(gold.lower().split())\n",
    "        if len(pred_tokens) > 0 and len(gold_tokens) > 0:\n",
    "            precision = len(pred_tokens & gold_tokens) / len(pred_tokens)\n",
    "            recall = len(pred_tokens & gold_tokens) / len(gold_tokens)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        else:\n",
    "            f1 = 0\n",
    "        baseline_f1.append(f1)\n",
    "        \n",
    "        # TempRALM\n",
    "        temp_docs, _ = retrieve_tempralm(q, q_year)\n",
    "        temp_ans = generate_answer(q, temp_docs)\n",
    "        tempralm_exact.append(1 if exact_match(temp_ans, gold) else 0)\n",
    "        \n",
    "        # F1 score\n",
    "        pred_tokens = set(temp_ans.lower().split())\n",
    "        gold_tokens = set(gold.lower().split())\n",
    "        if len(pred_tokens) > 0 and len(gold_tokens) > 0:\n",
    "            precision = len(pred_tokens & gold_tokens) / len(pred_tokens)\n",
    "            recall = len(pred_tokens & gold_tokens) / len(gold_tokens)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        else:\n",
    "            f1 = 0\n",
    "        tempralm_f1.append(f1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXACT MATCH vs F1 COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nBaseline:\")\n",
    "    print(f\"  Exact Match: {np.mean(baseline_exact):.2%}\")\n",
    "    print(f\"  F1 Score: {np.mean(baseline_f1):.2%}\")\n",
    "    \n",
    "    print(f\"\\nTempRALM:\")\n",
    "    print(f\"  Exact Match: {np.mean(tempralm_exact):.2%}\")\n",
    "    print(f\"  F1 Score: {np.mean(tempralm_f1):.2%}\")\n",
    "    \n",
    "    print(f\"\\nF1 Improvement: {(np.mean(tempralm_f1) - np.mean(baseline_f1))*100:+.1f} points\")\n",
    "    \n",
    "    return {\n",
    "        'baseline_f1': np.mean(baseline_f1),\n",
    "        'tempralm_f1': np.mean(tempralm_f1)\n",
    "    }\n",
    "\n",
    "\n",
    "# ============= RUN DIAGNOSTICS =============\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RUNNING DIAGNOSTIC ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check temporal coverage\n",
    "coverage = check_temporal_coverage(n=100)\n",
    "\n",
    "# 2. Analyze failures\n",
    "failures = analyze_failures(n=50)\n",
    "\n",
    "# 3. Compare retrieval directly\n",
    "retrieval_comp = compare_retrieval_directly(n=50)\n",
    "\n",
    "# 4. Try F1 scoring\n",
    "f1_results = evaluate_with_relaxed_matching(n=100)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n1. Temporal Coverage: {coverage['coverage']*100:.1f}% of questions have both query & doc years\")\n",
    "print(f\"2. Retrieval helps: TempRALM retrieves gold better in {retrieval_comp['better']} cases\")\n",
    "print(f\"3. With F1 metric: Baseline {f1_results['baseline_f1']:.1%}, TempRALM {f1_results['tempralm_f1']:.1%}\")\n",
    "\n",
    "print(\"\\n Key Insights:\")\n",
    "if coverage['coverage'] < 0.7:\n",
    "    print(\"Many questions lack temporal info - limits your approach's effectiveness\")\n",
    "if retrieval_comp['better'] < 5:\n",
    "    print(\"Temporal scoring not improving retrieval much\")\n",
    "if f1_results['tempralm_f1'] > f1_results['baseline_f1'] * 1.1:\n",
    "    print(\" F1 shows better improvement than exact match - predictions are partially correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fcc9c-db1d-4479-ab80-cc5264d938cb",
   "metadata": {},
   "source": [
    "1. Added temporal metadata\n",
    "added time information (like years) to both:\n",
    "the query (query_year)  when the question is asked\n",
    "the documents/passages (doc_year)  when the content was written or relevant\n",
    "This gives the model temporal awareness  it knows when things happened.\n",
    "\n",
    "2. Combined semantic + temporal similarity\n",
    "Normally in vanilla RAG, retrieval is based only on semantic similarity (cosine similarity of embeddings).\n",
    "But in Temporal RAG (TempRALM), you modified this by adding a temporal penalty or weight.\n",
    "\n",
    "So instead of:\n",
    "sim(q,d)=cos(q,d)\n",
    "used something like:\n",
    "temporal_sim(q,d)=cos(q,d)t\n",
    "where  = scaling factor (temporal penalty strength)\n",
    "t & d = years of query and document\n",
    "\n",
    "This means documents further away in time get lower scores, even if semantically similar.\n",
    "Encoded temporal grounding into your retriever.\n",
    "\n",
    "3. Retrieved the top-k most relevant docs\n",
    "Then used FAISS to:\n",
    "Compute these temporal-adjusted similarities\n",
    "Retrieve top k documents\n",
    "Pass them as context to the generator (T5 model)\n",
    "\n",
    "4. Generated the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a0d64-34b2-4e65-bde2-e331fbdcd8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
